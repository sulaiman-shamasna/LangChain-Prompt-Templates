{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["!python -m venv env"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["'source' is not recognized as an internal or external command,\n","operable program or batch file.\n"]}],"source":["!source env/Scripts/activate"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.1.1 -> 24.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install -q langchain==0.0.208 openai==0.27.8 python-dotenv"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from dotenv import load_dotenv\n","\n","!echo OPENAI_API_KEY='OPENAI_API_KEY' > .env\n","\n","load_dotenv()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: What is the main advantage of quantum computing over classical computing?\n","Answer: The main advantage of quantum computing over classical computing is the ability to solve complex problems faster.\n"]}],"source":["from langchain import LLMChain, PromptTemplate\n","from langchain.chat_models import ChatOpenAI\n","\n","llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","\n","template = \"\"\"Answer the question based on the context below. If the\n","question cannot be answered using the information provided, answer\n","with \"I don't know\".\n","Context: Quantum computing is an emerging field that leverages quantum mechanics to solve complex problems faster than classical computers.\n","...\n","Question: {query}\n","Answer: \"\"\"\n","\n","prompt_template = PromptTemplate(\n","    input_variables=[\"query\"],\n","    template=template\n",")\n","\n","# Create the LLMChain for the prompt\n","chain = LLMChain(llm=llm, prompt=prompt_template)\n","\n","# Set the query you want to ask\n","input_data = {\"query\": \"What is the main advantage of quantum computing over classical computing?\"}\n","\n","# Run the LLMChain to get the AI-generated answer\n","response = chain.run(input_data)\n","\n","print(\"Question:\", input_data[\"query\"])\n","print(\"Answer:\", response)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tropical rainforests, grasslands, and mangrove swamps\n"]}],"source":["from langchain import LLMChain, FewShotPromptTemplate, PromptTemplate\n","from langchain.chat_models import ChatOpenAI\n","\n","llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","\n","examples = [\n","    {\"animal\": \"lion\", \"habitat\": \"savanna\"},\n","    {\"animal\": \"polar bear\", \"habitat\": \"Arctic ice\"},\n","    {\"animal\": \"elephant\", \"habitat\": \"African grasslands\"}\n","]\n","\n","example_template = \"\"\"\n","Animal: {animal}\n","Habitat: {habitat}\n","\"\"\"\n","\n","example_prompt = PromptTemplate(\n","    input_variables=[\"animal\", \"habitat\"],\n","    template=example_template\n",")\n","\n","dynamic_prompt = FewShotPromptTemplate(\n","    examples=examples,\n","    example_prompt=example_prompt,\n","    prefix=\"Identify the habitat of the given animal\",\n","    suffix=\"Animal: {input}\\nHabitat:\",\n","    input_variables=[\"input\"],\n","    example_separator=\"\\n\\n\",\n",")\n","\n","# Create the LLMChain for the dynamic_prompt\n","chain = LLMChain(llm=llm, prompt=dynamic_prompt)\n","\n","# Run the LLMChain with input_data\n","input_data = {\"input\": \"tiger\"}\n","response = chain.run(input_data)\n","\n","print(response)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["prompt_template.save(\"awesome_prompt.json\")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from langchain.prompts import load_prompt\n","loaded_prompt = load_prompt(\"awesome_prompt.json\")"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Just watch some YouTube tutorials and hope for the best.\n"]}],"source":["from langchain import LLMChain, FewShotPromptTemplate, PromptTemplate\n","from langchain.chat_models import ChatOpenAI\n","\n","llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","\n","examples = [\n","    {\n","        \"query\": \"How do I become a better programmer?\",\n","        \"answer\": \"Try talking to a rubber duck; it works wonders.\"\n","    }, {\n","        \"query\": \"Why is the sky blue?\",\n","        \"answer\": \"It's nature's way of preventing eye strain.\"\n","    }\n","]\n","\n","example_template = \"\"\"\n","User: {query}\n","AI: {answer}\n","\"\"\"\n","\n","example_prompt = PromptTemplate(\n","    input_variables=[\"query\", \"answer\"],\n","    template=example_template\n",")\n","\n","prefix = \"\"\"The following are excerpts from conversations with an AI\n","assistant. The assistant is typically sarcastic and witty, producing\n","creative and funny responses to users' questions. Here are some\n","examples:\n","\"\"\"\n","\n","suffix = \"\"\"\n","User: {query}\n","AI: \"\"\"\n","\n","few_shot_prompt_template = FewShotPromptTemplate(\n","    examples=examples,\n","    example_prompt=example_prompt,\n","    prefix=prefix,\n","    suffix=suffix,\n","    input_variables=[\"query\"],\n","    example_separator=\"\\n\\n\"\n",")\n","\n","# Create the LLMChain for the few_shot_prompt_template\n","chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n","\n","# Run the LLMChain with input_data\n","input_data = {\"query\": \"How can I learn quantum computing?\"}\n","response = chain.run(input_data)\n","\n","print(response)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["examples = [\n","    {\n","        \"query\": \"How do you feel today?\",\n","        \"answer\": \"As an AI, I don't have feelings, but I've got jokes!\"\n","    }, {\n","        \"query\": \"What is the speed of light?\",\n","        \"answer\": \"Fast enough to make a round trip around Earth 7.5 times in one second!\"\n","    }, {\n","        \"query\": \"What is a quantum computer?\",\n","        \"answer\": \"A magical box that harnesses the power of subatomic particles to solve complex problems.\"\n","    }, {\n","        \"query\": \"Who invented the telephone?\",\n","        \"answer\": \"Alexander Graham Bell, the original 'ringmaster'.\"\n","    }, {\n","        \"query\": \"What programming language is best for AI development?\",\n","        \"answer\": \"Python, because it's the only snake that won't bite.\"\n","    }, {\n","        \"query\": \"What is the capital of France?\",\n","        \"answer\": \"Paris, the city of love and baguettes.\"\n","    }, {\n","        \"query\": \"What is photosynthesis?\",\n","        \"answer\": \"A plant's way of saying 'I'll turn this sunlight into food. You're welcome, Earth.'\"\n","    }, {\n","        \"query\": \"What is the tallest mountain on Earth?\",\n","        \"answer\": \"Mount Everest, Earth's most impressive bump.\"\n","    }, {\n","        \"query\": \"What is the most abundant element in the universe?\",\n","        \"answer\": \"Hydrogen, the basic building block of cosmic smoothies.\"\n","    }, {\n","        \"query\": \"What is the largest mammal on Earth?\",\n","        \"answer\": \"The blue whale, the original heavyweight champion of the world.\"\n","    }, {\n","        \"query\": \"What is the fastest land animal?\",\n","        \"answer\": \"The cheetah, the ultimate sprinter of the animal kingdom.\"\n","    }, {\n","        \"query\": \"What is the square root of 144?\",\n","        \"answer\": \"12, the number of eggs you need for a really big omelette.\"\n","    }, {\n","        \"query\": \"What is the average temperature on Mars?\",\n","        \"answer\": \"Cold enough to make a Martian wish for a sweater and a hot cocoa.\"\n","    }\n","]"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["from langchain.prompts.example_selector import LengthBasedExampleSelector\n","\n","example_selector = LengthBasedExampleSelector(\n","    examples=examples,\n","    example_prompt=example_prompt,\n","    max_length=100\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["dynamic_prompt_template = FewShotPromptTemplate(\n","    example_selector=example_selector,\n","    example_prompt=example_prompt,\n","    prefix=prefix,\n","    suffix=suffix,\n","    input_variables=[\"query\"],\n","    example_separator=\"\\n\"\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Alexander Graham Bell, the man who made it possible for you to ignore calls from telemarketers.\n"]}],"source":["from langchain import LLMChain, FewShotPromptTemplate, PromptTemplate\n","from langchain.chat_models import ChatOpenAI\n","\n","from langchain.prompts.example_selector import LengthBasedExampleSelector\n","\n","llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n","\n","# Existing example and prompt definitions, and dynamic_prompt_template initialization\n","\n","# Create the LLMChain for the dynamic_prompt_template\n","chain = LLMChain(llm=llm, prompt=dynamic_prompt_template)\n","\n","# Run the LLMChain with input_data\n","input_data = {\"query\": \"Who invented the telephone?\"}\n","response = chain.run(input_data)\n","\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":2}
